<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Techkshetra - Dalmia</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://docs.opencv.org/4.9.0/opencv.js"></script>
    <style>
        h1 {
            position: relative;
            text-align: center;
            color: white;
            font-size: 8em;
            transition: 0.2s;
            font-family: Arial, Helvetica, sans-serif;
        }

        h1:hover {
            transform: translateY(-10px);
            text-shadow: 0 2px 4px rgba(64, 224, 208, 0.4),
                        0 4px 8px rgba(0, 191, 255, 0.4), 
                        0 8px 16px rgba(30, 144, 255, 0.5),
                        0 16px 32px rgba(0, 255, 255, 0.6);
            transition: all 0.4s cubic-bezier(0.4, 0, 0.2, 1);
            color: #ffffff;
            letter-spacing: 2px;
            animation: glow 2.5s ease-in-out infinite alternate;
            filter: brightness(1.2);
        }

        @keyframes glow {
            from {
                text-shadow: 0 0 3px #00ffff,
                           0 0 6px #00ffff,
                           0 0 9px #00bfff;
            }
            to {
                text-shadow: 0 0 5px #40e0d0,
                           0 0 10px #40e0d0,
                           0 0 15px #7fffd4;
            }
        }
        body {
            background-image: url("/static/assets/img14.jpg");
            background-size: cover;
            background-position: center;
            background-repeat: no-repeat;
            background-attachment: fixed;
            margin: 0;
            padding: 0;
            min-height: 100vh;
            width: 100vw;
            background-color: rgba(0,0,0,0.6);
            background-blend-mode: overlay;
        }

        .button-disabled {
            opacity: 0.6;
            cursor: not-allowed;
        }

        #webcam-container {
            display: none;
            position: fixed;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            z-index: 1000;
            background: rgba(0, 0, 0, 0.8);
            padding: 20px;
            border: 2px solid #00ffff;
            border-radius: 10px;
        }

        #webcam-container.active {
            display: block;
        }

        #videoElement {
            width: 640px;
            height: 480px;
            transform: scaleX(-1);
        }

        #overlay-canvas {
            position: absolute;
            top: 20px;
            left: 20px;
            pointer-events: none;
        }

        .close-button {
            position: absolute;
            top: 10px;
            right: 10px;
            background: none;
            border: none;
            color: #00ffff;
            font-size: 24px;
            cursor: pointer;
            z-index: 1001;
        }
    </style>
</head>
<body class="min-h-screen">
    <div class="container mx-auto px-4 py-8 md:py-16">
        <!-- Main Header Section -->
        <div class="text-center mb-8 md:mb-16">
            <h1 class="text-4xl md:text-6xl lg:text-8xl font-extrabold text-transparent bg-clip-text bg-gradient-to-r from-blue-400 to-teal-600 mb-6 tracking-wider hover:scale-105 transition-transform duration-300">
                DALMIA'S
                <span class="block bg-gradient-to-r from-indigo-400 to-cyan-500 bg-clip-text text-transparent mt-4 transform hover:translate-y-[-5px] transition-all duration-300">PRESENTS</span>
            </h1>
        </div>

        <!-- Techkshetra Section -->
        <div class="text-center mb-8 md:mb-16">
            <h2 class="text-4xl md:text-6xl lg:text-8xl font-extrabold text-white mb-4 tracking-wider hover:scale-105 transition-transform duration-300 animate-glow" style="text-shadow: 0 0 10px #00ffff, 0 0 20px #00ffff, 0 0 30px #00ffff;">
                TECHKSHETRA
            </h2>
            <p class="text-xl md:text-2xl text-white font-light tracking-wide glow">
                Welcome to our Tech Event
            </p>
        </div>

        <div class="text-center text-white">
            <button id="startButton" onclick="startExperience()"
                    class="bg-transparent border-2 border-white hover:bg-white text-white hover:text-black 
                           font-bold py-4 px-8 rounded-lg tracking-wider
                           transition-all duration-300 transform hover:scale-110
                           shadow-lg hover:shadow-xl"> 
                BEGIN THE EXPERIENCE
            </button>
            <p id="errorMessage" class="mt-4 text-red-500 hidden"></p>
        </div>
    </div>

    <!-- Webcam Container -->
    <div id="webcam-container">
        <button class="close-button" onclick="closeWebcam()">Ã—</button>
        <video id="videoElement" autoplay playsinline></video>
        <canvas id="overlay-canvas"></canvas>
    </div>

    <script>
        let startTime;
        let faceDetected = false;
        let video;
        let stream;
        let detector;
        let animationFrame;
        
        async function startExperience() {
            const button = document.getElementById('startButton');
            const errorMessage = document.getElementById('errorMessage');
            const container = document.getElementById('webcam-container');
            
            try {
                button.disabled = true;
                button.classList.add('button-disabled');
                errorMessage.classList.add('hidden');

                // Load face detection model
                await loadFaceDetectionModel();
                
                // Request webcam access
                stream = await navigator.mediaDevices.getUserMedia({ video: true });
                video = document.getElementById('videoElement');
                video.srcObject = stream;
                
                // Show webcam container
                container.classList.add('active');
                
                // Start detection
                startTime = Date.now();
                detectFaces();
                
            } catch (error) {
                console.error(error);
                errorMessage.textContent = 'Failed to start the experience. Please allow camera access and try again.';
                errorMessage.classList.remove('hidden');
                button.disabled = false;
                button.classList.remove('button-disabled');
            }
        }

        async function loadFaceDetectionModel() {
            // Load OpenCV.js face detection classifier
            detector = new cv.CascadeClassifier();
            const response = await fetch('/static/haarcascade_frontalface_default.xml');
            const buffer = await response.arrayBuffer();
            detector.load(new Uint8Array(buffer));
        }

        function detectFaces() {
            const canvas = document.getElementById('overlay-canvas');
            const ctx = canvas.getContext('2d');
            const elapsed = (Date.now() - startTime) / 1000;

            // Clear previous frame
            ctx.clearRect(0, 0, canvas.width, canvas.height);

            // Process video frame
            try {
                const src = new cv.Mat(video.height, video.width, cv.CV_8UC4);
                const gray = new cv.Mat();
                const faces = new cv.RectVector();

                // Capture video frame
                const cap = new cv.VideoCapture(video);
                cap.read(src);

                // Convert to grayscale
                cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);

                // Detect faces
                detector.detectMultiScale(gray, faces);

                // Draw overlay effects
                drawTechBorder(ctx);
                if (!faceDetected) {
                    drawScanLine(ctx, elapsed);
                }

                // Process detected faces
                if (faces.size() > 0 && !faceDetected) {
                    faceDetected = true;
                    drawSuccessAnimation(ctx);
                    setTimeout(closeWebcam, 2000);
                } else if (!faceDetected && elapsed > 20) {
                    closeWebcam();
                }

                // Draw status text
                drawStatusText(ctx, faceDetected, elapsed);

                // Cleanup
                src.delete();
                gray.delete();
                faces.delete();

            } catch (err) {
                console.error(err);
            }

            // Continue animation
            if (!faceDetected) {
                animationFrame = requestAnimationFrame(detectFaces);
            }
        }

        function drawTechBorder(ctx) {
            // Implementation of tech border drawing
            // Similar to Python implementation
        }

        function drawScanLine(ctx, elapsed) {
            // Implementation of scan line effect
            // Similar to Python implementation
        }

        function drawSuccessAnimation(ctx) {
            // Implementation of success animation
            // Similar to Python implementation
        }

        function drawStatusText(ctx, faceDetected, elapsed) {
            // Implementation of status text drawing
            // Similar to Python implementation
        }

        function closeWebcam() {
            const container = document.getElementById('webcam-container');
            container.classList.remove('active');
            
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
            }
            
            if (animationFrame) {
                cancelAnimationFrame(animationFrame);
            }

            const button = document.getElementById('startButton');
            button.disabled = false;
            button.classList.remove('button-disabled');
        }
    </script>
</body>
</html>
